{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2019 Mohamed-Achref MAIZA                                                                                                                  # IGNORE_COPYRIGHT: cleared by OSS licensing\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Label Image Classification with TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-label classification problems can be thought of as many independant binary classification problems to solve at the same time.  \n",
    "\n",
    "In this notebook, we show how to build a machine learning model that predicts the genre of a movie given its poster.  \n",
    "For each movie poster, the model will assign zero or many labels (Drama, Action, Romance, etc.).  \n",
    "This is different from traditional multi-class classification problems where each observation ends up having one single label.  \n",
    "\n",
    "What is important here is to think about an evaluation metric to measure the performance of our system and be able to directly optimize for it. We show the importance of using what we call the macro soft-F1 loss over a batch of training observations. This loss will lead to a multi-label classification performance that does not really depend on the choice of an optimal decision threshold adapted to each label.  \n",
    "If you are deploying a classification system in production, this will save you a lot of effort as you will no longer need to update the decision thresholds dynamically on new coming data.\n",
    "\n",
    "Our workflow will look like this:\n",
    "1. Data collection\n",
    "2. Data preparation\n",
    "3. Create a fast input pipeline in TensorFlow\n",
    "4. Build up the model\n",
    "    * Get a transfer learning layer using TensorFlow Hub\n",
    "    * Stack a multi-label neural network classifier on top\n",
    "5. Model training and evaluation\n",
    "7. Understand the role of macro soft-F1 loss\n",
    "8. Export and save tf.keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==0.25.0 in /opt/conda/lib/python3.7/site-packages (0.25.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.0) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.0) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==0.25.0) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in /opt/conda/lib/python3.7/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "#!pip3 uninstall pandas\n",
    "!pip3 install pandas==0.25.0\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from tensorflow.keras import layers\n",
    "import csv\n",
    "\n",
    "!pip3 install utils\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.3.0\n",
      "0.25.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the movie posters dataset obtained from Kaggle [Movie Genre from its Poster](https://www.kaggle.com/neha1703/movie-genre-from-its-poster).\n",
    "\n",
    "You can get a csv file named 'MovieGenre.csv' which groups together information about movies including links to download posters as well as their genres.\n",
    "These information were collected from [IMDB website](https://www.imdb.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Imdb Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>IMDB Score</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.imdb.com/title/tt114709</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Animation|Adventure|Comedy</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113497</td>\n",
       "      <td>http://www.imdb.com/title/tt113497</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Action|Adventure|Family</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113228</td>\n",
       "      <td>http://www.imdb.com/title/tt113228</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114885</td>\n",
       "      <td>http://www.imdb.com/title/tt114885</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113041</td>\n",
       "      <td>http://www.imdb.com/title/tt113041</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Comedy|Family|Romance</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbId                           Imdb Link  \\\n",
       "0  114709  http://www.imdb.com/title/tt114709   \n",
       "1  113497  http://www.imdb.com/title/tt113497   \n",
       "2  113228  http://www.imdb.com/title/tt113228   \n",
       "3  114885  http://www.imdb.com/title/tt114885   \n",
       "4  113041  http://www.imdb.com/title/tt113041   \n",
       "\n",
       "                                Title  IMDB Score                       Genre  \\\n",
       "0                    Toy Story (1995)         8.3  Animation|Adventure|Comedy   \n",
       "1                      Jumanji (1995)         6.9     Action|Adventure|Family   \n",
       "2             Grumpier Old Men (1995)         6.6              Comedy|Romance   \n",
       "3            Waiting to Exhale (1995)         5.7        Comedy|Drama|Romance   \n",
       "4  Father of the Bride Part II (1995)         5.9       Comedy|Family|Romance   \n",
       "\n",
       "                                              Poster  \n",
       "0  https://images-na.ssl-images-amazon.com/images...  \n",
       "1  https://images-na.ssl-images-amazon.com/images...  \n",
       "2  https://images-na.ssl-images-amazon.com/images...  \n",
       "3  https://images-na.ssl-images-amazon.com/images...  \n",
       "4  https://images-na.ssl-images-amazon.com/images...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\"/home/jupyter/multi-label/data/movie_poster/MovieGenre.csv\",encoding=\"ISO-8859-1\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Imdb Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>IMDB Score</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.imdb.com/title/tt114709</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Animation|Adventure|Comedy</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113497</td>\n",
       "      <td>http://www.imdb.com/title/tt113497</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Action|Adventure|Family</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113228</td>\n",
       "      <td>http://www.imdb.com/title/tt113228</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbId                           Imdb Link                    Title  \\\n",
       "0  114709  http://www.imdb.com/title/tt114709         Toy Story (1995)   \n",
       "1  113497  http://www.imdb.com/title/tt113497           Jumanji (1995)   \n",
       "2  113228  http://www.imdb.com/title/tt113228  Grumpier Old Men (1995)   \n",
       "\n",
       "   IMDB Score                       Genre  \\\n",
       "0         8.3  Animation|Adventure|Comedy   \n",
       "1         6.9     Action|Adventure|Family   \n",
       "2         6.6              Comedy|Romance   \n",
       "\n",
       "                                              Poster  \n",
       "0  https://images-na.ssl-images-amazon.com/images...  \n",
       "1  https://images-na.ssl-images-amazon.com/images...  \n",
       "2  https://images-na.ssl-images-amazon.com/images...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows having a missing Id, Genre or Poster \n",
    "movies.dropna(subset=['imdbId', 'Genre', 'Poster'], inplace=True)\n",
    "# Remove \"Adult\" movies\n",
    "movies.drop(movies[movies['Genre'].str.contains('Adult')].index, inplace=True)\n",
    "# Show some examples\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prefer downloading multiple images in parallel to save time.  \n",
    "There is a helper function called `download_parallel` in the `utils` module that does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_parallel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a6a34e8c74ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/movie_poster/images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Download in parallel and return the successful subset of the movies dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'download_parallel' is not defined"
     ]
    }
   ],
   "source": [
    "# Define destination folder\n",
    "destination = './data/movie_poster/images'\n",
    "# Download in parallel and return the successful subset of the movies dataframe\n",
    "movies = download_parallel(movies, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If the number of errors is not 0, it means that some movie posters could not be downloaded.  \n",
    "These posters are then removed from the dataset and the movies dataframe is filtered to keep only successful downloads.  \n",
    "The final movies dataframe with all downloaded posters will be saved to csv in the `munge` directory.  \n",
    "So, next time you run this notebook you do not need to download the images again but just read the movies dataframe from the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final number of movie posters to keep:\", len(movies))\n",
    "\n",
    "# Save the final movies dataframe to disk\n",
    "munge_dir = \"./munge\"\n",
    "if not os.path.exists(munge_dir):\n",
    "    os.makedirs(munge_dir)\n",
    "movies.to_csv(os.path.join(munge_dir, \"movies.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start here if the dataset is already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"./munge/movies.csv\")\n",
    "print(\"Number of movie posters in last download: {}\\n\".format(len(movies)))\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "The following preparation steps aim to create training and validation sets that can be used for machine learning.  \n",
    "For example, if a movie genre is rare, we will remove it from the target variable.  \n",
    "The model will not learn how to predict that genre if the data covering it is insufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze label frequencies\n",
    "Let's examine which movie genres are the most frequent and which ones are rare.  \n",
    "The following graph will rank all labels in descending frequency order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label frequencies in descending order\n",
    "label_freq = movies['Genre'].apply(lambda s: str(s).split('|')).explode().value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Bar plot\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.barplot(y=label_freq.index.values, x=label_freq, order=label_freq.index)\n",
    "plt.title(\"Label frequency\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove infrequent labels\n",
    "We will consider as a rare label every label that is covered by less than 1000 posters in our dataset.  \n",
    "We will assume that these labels are very hard to predict due to lack of sufficient data.  \n",
    "The model that we will train later will not focus on predicting these labels.  \n",
    "So, we need to make some transformation in the label column (Genre) where we ignore infrequent labels by hiding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of rare labels\n",
    "rare = list(label_freq[label_freq<1000].index)\n",
    "print(\"We will be ignoring these rare labels:\", rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Genre into a list of labels and remove the rare ones\n",
    "movies['Genre'] = movies['Genre'].apply(lambda s: [l for l in str(s).split('|') if l not in rare])\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / val split\n",
    "Splitting the modeling data into training and validation is common in machine learning practice.  \n",
    "We will be allocating 80% of the images for training and 20% for validation.  \n",
    "Usually, we keep a final test set to communicate performance results but we will not really need it in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(movies['imdbId'], movies['Genre'], test_size=0.2, random_state=44)\n",
    "print(\"Number of posters for training: \", len(X_train))\n",
    "print(\"Number of posters for validation: \", len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to complete the full path to locate training and test images from the current working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [os.path.join('./data/movie_poster/images', str(f)+'.jpg') for f in X_train]\n",
    "X_val = [os.path.join('./data/movie_poster/images', str(f)+'.jpg') for f in X_val]\n",
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the targets to be a list of list of strings in order to fit a binarizer (multi-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(y_train)\n",
    "y_val = list(y_val)\n",
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image examples\n",
    "Let's display some examples of training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 8 # Maximum number of images to display\n",
    "ncols = 4 # Number of columns in display\n",
    "nrows = nobs//ncols # Number of rows in display\n",
    "\n",
    "style.use(\"default\")\n",
    "plt.figure(figsize=(12,4*nrows))\n",
    "for i in range(nrows*ncols):\n",
    "    ax = plt.subplot(nrows, ncols, i+1)\n",
    "    plt.imshow(Image.open(X_train[i]))\n",
    "    plt.title(y_train[i], size=10)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding\n",
    "The original targets are lists of strings that can be easily understood by humans.  \n",
    "But, if we want to build and train a neural network we need to create binary labels (multi-hot encoding).  \n",
    "This is critical for multi-label classification.  \n",
    "\n",
    "In order to binarize our labels, we will be using scikit-learn's MultiLabelBinarizer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the multi-label binarizer on the training set\n",
    "print(\"Labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Loop over all labels and show them\n",
    "N_LABELS = len(mlb.classes_)\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the targets of the training and test sets\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if everything worked correctly (We should obtain binary targets instead of list of strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print example of movie posters and their binary targets\n",
    "for i in range(3):\n",
    "    print(X_train[i], y_train_bin[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast input pipeline\n",
    "\n",
    "If you are familiar with [keras.preprocessing](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing) you may know the image data iterators (E.g. [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator), [DirectoryIterator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator)).  \n",
    "These iterators are convenient for multi-class classfication where the image directory contains one subdirectory for each class.  \n",
    "But, in the case of multi-label classification, having an image directory that respects this structure is not possible because one observation can belong to multiple classes at the same time.\n",
    "\n",
    "That is where the [tf.data](https://www.tensorflow.org/guide/data) API has the upper hand.\n",
    "\n",
    "* It is faster.\n",
    "* It provides fine-grained control.\n",
    "* It is well integrated with the rest of TensorFlow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to write some function to parse image files and generate a tensor representing the features and a tensor representing the labels.  \n",
    "* In this function we can resize the image to adapt to the input expected by the model.  \n",
    "* We can also normalize the pixel values to be between 0 and 1. This is a common practice that helps speed up the convergence of training.  \n",
    "If we consider every pixel as a feature, we would like these features to have a similar range so that the gradients don't go out of control and that we only need one global learning rate multiplier.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 3 # Keep RGB color channels to match the input format of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename, label):\n",
    "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
    "    Args:\n",
    "        filename: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model on our dataset we want the data to be:\n",
    "* Well shuffled\n",
    "* Batched\n",
    "* Batches to be available as soon as possible.\n",
    "\n",
    "These features can be easily added using the [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data) abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AUTOTUNE` will adapt the preprocessing and prefetching workload to model training and batch consumption.  \n",
    "The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step.  \n",
    "`AUTOTUNE` will prompt the tf.data runtime to tune the value dynamically at runtime and reduce GPU and CPU idle time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a function that generates training and validation datasets for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        \n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, y_train_bin)\n",
    "val_ds = create_dataset(X_val, y_val_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch will be a pair of arrays (one that holds the features and another one that holds the labels).  \n",
    "The features array will be of shape (BATCH_SIZE, IMG_SIZE, IMG_SIZE, CHANNELS).  \n",
    "The labels array will be of shape (BATCH_SIZE, N_LABELS) where N_LABELS is the maximum number of labels.  \n",
    "Let's verify the shapes of these arrays by analyzing the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, l in train_ds.take(1):\n",
    "    print(\"Shape of features array:\", f.numpy().shape)\n",
    "    print(\"Shape of labels array:\", l.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building (Transfer learning)\n",
    "Instead of building and training a new model from scratch, we will use a pre-trained model in a process called transfer learning.  \n",
    "The majority of pre-trained models for vision applications were trained on [ImageNet](http://www.image-net.org/) which is a large image database with more than 14 million images divided into more than 20 thousand categories. The idea behind transfer learning is that these models, because they were trained in a context of large and general classification task, can then be used to address a more specific task by extracting and transfering meaningful features that were previously learned. All we need to do is acquire a pre-trained model and simply add a new classfier on top of it. The new classification head will be trained from scratch so that we repurpose the objective to our multi-label classfication task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Aknowledgement**  \n",
    "TensorFlow core team did a great job sharing pre-trained models and tutorials on how to use them with `tf.keras` API.  \n",
    "https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub  \n",
    "https://www.tensorflow.org/tutorials/images/transfer_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow Hub](https://www.tensorflow.org/hub/) is a library that allows to publish and reuse pre-made ML components.  \n",
    "Using TF.Hub it is simple to retrain the top layer of a pre-trained model to recognize the classes in a new dataset.  \n",
    "TensorFlow Hub also distributes models without the top classification layer. These can be used to easily perform transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the headless model\n",
    "\n",
    "Any [Tensorflow 2 compatible image feature vector URL](https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) from tfhub.dev can be interesting for our dataset.  \n",
    "The only condition is to insure that the shape of image features in our prepared dataset matches the expected input shape of the model we want to reuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's prepare the feature extractor. We will be using a pre-trained [instance of MobileNet V2](https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4) with a depth multiplier of 1.0 and an input size of 224x224. MobileNet V2 is actually a large family of neural network architectures that were mainly designed to speed up on-device inference. They come in different sizes depending on the depth multiplier (number of features in hidden convolutional layers) and the size of input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature extractor accepts images of shape (224, 224, 3) and returns a 1280-length vector for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should freeze the variables in the feature extractor layer, so that the training only modifies the new classification layers.  \n",
    "Usually, it is a good practice when working with datasets that are very small compared to the orginal dataset the feature extractor was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Fine tuning the feature extractor is only recommended if the training dataset is large and very similar to the original ImageNet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach a classification head\n",
    "\n",
    "Now, we can wrap the feature extractor layer in a `tf.keras.Sequential` model and add new layers on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(1024, activation='relu', name='hidden_layer'),\n",
    "    layers.Dense(N_LABELS, activation='sigmoid', name='output')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2.2M parameters in MobileNet are frozen, but there are 1.3K trainable parameters in the dense layers.  \n",
    "We apply the sigmoid activation function in the final neurons to ouput a probability score for each label apart.  \n",
    "Every final neuron will act as a seperate binary classifier for one single label, even though the features extracted are common to all final neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the result of running a forward propagation on the first observation of the first batch.  \n",
    "Normally, we should see a probability score for each genre and that probability scores do not necessarily sum up to 1.  \n",
    "This is different from using a softmax layer in multi-class classification where the sum of output probability scores is equal to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_ds:\n",
    "    print(model.predict(batch)[:1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous steps, we have prepared our dataset and composed a model by attaching a multi-label neural network classifier on top of a pre-trained network (without output). We can now proceed to training our model but we need to define two major functions:\n",
    "* **A loss function:** We need it to measure the model error (cost) on traning batches.  \n",
    "It has to be differentiable in order to [backpropagate](https://en.wikipedia.org/wiki/Backpropagation) the error in the neural network and update the weights.\n",
    "* **An evaluation function:** It should represent the final evaluation metric we really care about.  \n",
    "Unlike the loss function it has to be more intuitive to understand what the model performance will look like in the real world.\n",
    "\n",
    "The purpose of this notebook is not only to share a general design for multi-label classfication but also to investigate the advantage of customizing the choice of the loss function to optimize directly for the evaluation metric we care about.\n",
    "\n",
    "Let's say we need the `F1-score` to evaluate the performance of the model on each label. The [F1-score](https://en.wikipedia.org/wiki/F1_score) is the harmonic mean of `Precision` and `Recall`. And, the computation of Precision and Recall takes into account the number of `True Positives (TP)`, the number of `False Positives (FP)` and the number of `False Negatives (FN)` when considering any specific label.  \n",
    "https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "<img src=\"./img/confusion_matrix.png\" width=\"600\">\n",
    "\n",
    "We compute as many F1-scores as the total number of labels and then average them to get what we call a `Macro F1-score`. It is reasonable to take the average over all labels if they have the same importance in the multi-label classification task.\n",
    "\n",
    "The problem of the F1-score is that it is not differentiable and so we cannot use it as a loss function to compute gradients and update the weights when training the model. This is because the F1-score needs binary predictions (0/1) to be measured. These binary predictions are obtained by applying a decision theshold on the probability scores generated by the model. For example, we can predict 1 (a movie is about Action) if the probability for Action is above the threshold of 0.5, otherwise we predict 0 (no Action).\n",
    "\n",
    "Usually we use the `binary cross-entropy loss` which represents the negative log likelihood <font color='grey'>-log(p)</font> of an observation being of a specific class with the model predicting a probability <font color='grey'>p</font> for that class.  Generally this loss works well and is widely used to train classifiers but it does not directly link and align with the F1-score we want to maximize.\n",
    "\n",
    "What we can do is modify the F1-score to make it differentiable. Instead of computing the number of True Positives, False Positives, False Negatives as discrete integer values, we can compute them as a continuous sum of likelihood values by using probabilities without applying any threshold.  \n",
    "To better understand this transformation let's see two examples.\n",
    "\n",
    "**Example 1:** If the target is 1 for a movie being Action and the model prediction for Action is 0.8, it will count as:\n",
    "* 0.8 x 1 = 0.8 TP (because the target is 1 and the model predicted 1 with 0.8 chance)\n",
    "* 0.2 x 1 = 0.2 FN (because the target is 1 and the model predicted 0 with 0.2 chance)\n",
    "* 0.8 x 0 = 0 FP (because the target is 1 not 0, condition negative is not valid)\n",
    "* 0.2 x 0 = 0 TN (because the target is 1 not 0, condition negative is not valid)\n",
    "\n",
    "**Example 2:** If the target is 0 for a movie being Action and the model prediction for Action is 0.8, it will count as:\n",
    "* 0.8 x 0 = 0 TP (because the target is 0 not 1, condition positive is not valid)\n",
    "* 0.2 x 0 = 0 FN (because the target is 0 not 1, condition positive is not valid)\n",
    "* 0.8 x 1 = 0.8 FP (because the target is 0 and the model predicted 1 with 0.8 chance)\n",
    "* 0.2 x 1 = 0.2 TN (because the target is 0 and the model predicted 0 with 0.2 chance)\n",
    "\n",
    "\n",
    "We will call this version of F1-score a `soft-F1-score`. Below, you can see the code that implements it on a batch of predictions in TensorFlow.  \n",
    "\n",
    "There are certain things to consider here:\n",
    "* The cost for each label is actually `1 - soft-F1` for that label. If we want to maximize soft-F1, we should minimize 1 - soft-F1.\n",
    "* You can replace Precision and Recall in the definition of soft-F1 and get a more direct formula based on terms of TP, FP and FN. The reason you want to do that is because the harmonic mean expression for F1 is undefined when TP = 0, but the translated expression is defined. F1 = 2.TP / (2.TP + FN + FP)\n",
    "* The total cost in a batch of observations will be the average cost on all labels. We will call it a `macro soft-F1 loss`.\n",
    "* We have to make sure that the batch size is big enough to see a representative macro soft-F1 loss while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def macro_soft_f1(y, y_hat):\n",
    "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
    "    Use probability values instead of binary predictions.\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        \n",
    "    Returns:\n",
    "        cost (scalar Tensor): value of the cost function for the batch\n",
    "    \"\"\"\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    y_hat = tf.cast(y_hat, tf.float32)\n",
    "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
    "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
    "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
    "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
    "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
    "    return macro_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will be training two models with the same architecture but two different loss functions:\n",
    "* The first one will be trained with the macro soft-F1 loss.    \n",
    "* The second one will be trained using the binary cross-entropy loss.  \n",
    "\n",
    "On the other hand, we may consider one single evaluation metric by default for both models: <font color='darkorange'>macro F1-score @ threshold 0.5</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "        \n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using the macro soft-F1 loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the learning rate and the number of training epochs (number of loops over the whole dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model to configure the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "  loss=macro_soft_f1,\n",
    "  metrics=[macro_f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we pass the training dataset of (features, labels) to fit the model and indicate a seperate dataset for validation.  \n",
    "The performance on the validation dataset will be measured after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=create_dataset(X_val, y_val_bin))\n",
    "print('\\nTraining took {}'.format(print_time(time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the learning curves on the training and validation sets when using the macro soft-F1 loss.  \n",
    "The funtion that plots learning curves was implemented and imported from `utils` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses, macro_f1s, val_macro_f1s = learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the performance measured on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Macro soft-F1 loss: %.2f\" %val_losses[-1])\n",
    "print(\"Macro F1-score: %.2f\" %val_macro_f1s[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You may have noticed here that a decrease in the macro soft-F1 loss to a level near 0.69 is associated with an increase in the macro F1-score to a level near 0.33. These two values almost complement to 1. Remember that the macro soft-F1 loss we defined was actually the macro of 1 - soft-F1 that we needed to minimize. This is a first indicator that the macro soft-F1 loss is directly optimizing for our evaluation metric which is the macro F1-score @ threshold 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using the binary cross-entropy loss\n",
    "\n",
    "We will train a similar model but this time, instead of using the macro soft-F1 loss, we will be using the binary cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bce = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(N_LABELS, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_bce.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n",
    "    loss=tf.keras.metrics.binary_crossentropy,\n",
    "    metrics=[macro_f1])\n",
    "    \n",
    "start = time()\n",
    "history_bce = model_bce.fit(train_ds,\n",
    "                            epochs=EPOCHS,\n",
    "                            validation_data=create_dataset(X_val, y_val_bin))\n",
    "print('\\nTraining took {}'.format(print_time(time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the learning curves on the training and validation datasets when using the binary cross entropy loss.  \n",
    "The function that plots learning curves was implemented in module `utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bce_losses, model_bce_val_losses, model_bce_macro_f1s, model_bce_val_macro_f1s = learning_curves(history_bce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the performance measured on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Macro soft-F1 loss: %.2f\" %model_bce_val_losses[-1])\n",
    "print(\"Macro F1-score: %.2f\" %model_bce_val_macro_f1s[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role of macro soft-F1 loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have trained two neural network models with same architecture.  \n",
    "The first one was optimizing directly for the macro F1-score, while the second one is more classic and optimized for the binary cross-entropy.  \n",
    "In both cases, the model trained will generate an independent probability score for each label when predicting the genre of a movie poster.  \n",
    "To create a final decision system, we need to pick a decision threshold between 0 and 1 for each label \n",
    "so as to transform each probability into a binary information. Usually the performance of the system depends on the choice of these decision thresholds.  \n",
    "So, let's examine how the system behaves on the validation set depending on the level where we set the threshold for each label.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function named `perf_grid` in the `utils` module that helps create the performance grid.  \n",
    "In the performance grid, thresholds increment from 0 to 1 by a step of 0.01 for each label.  \n",
    "For each threshold and for each label, we compute different measures (tp, fn, fp, precision, recall, f1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all label names\n",
    "label_names = mlb.classes_\n",
    "# Performance table with the first model (macro soft-f1 loss)\n",
    "grid = perf_grid(val_ds, y_val_bin, label_names, model)\n",
    "# Performance table with the second model (binary cross-entropy loss)\n",
    "grid_bce = perf_grid(val_ds, y_val_bin, label_names, model_bce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance grid when using the second model (optimized with the binary cross-entropy) looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bce.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each label, there is a threshold that maximizes the performance of the second model trained with the binary cross-entropy loss.  \n",
    "What labels have the highest maximum performance when using the second model with bce loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum F1-score for each label when using the second model and varying the threshold\n",
    "max_perf = grid_bce.groupby(['id', 'label', 'freq'])[['f1']].max().sort_values('f1', ascending=False).reset_index()\n",
    "max_perf.rename(columns={'f1':'f1max_bce'}, inplace=True)\n",
    "max_perf.style.background_gradient(subset=['freq', 'f1max_bce'], cmap=sns.light_palette(\"lightgreen\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any correlation between the frequency of a label in the dataset and the performance achieved on it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation between label frequency and optimal F1 with bce: %.2f\" %max_perf['freq'].corr(max_perf['f1max_bce']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the performance curves of the two different models on top 5 labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the index of top 5 labels with best optimal F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = max_perf.head(5)['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the performance curves of precision, recall, F1-score as a function of the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use(\"default\")\n",
    "for l in top5:\n",
    "    \n",
    "    label_grid = grid.loc[grid['id']==l, ['precision','recall','f1']]\n",
    "    label_grid = label_grid.reset_index().drop('index', axis=1)\n",
    "    \n",
    "    label_grid_bce = grid_bce.loc[grid_bce['id']==l, ['precision','recall','f1']]\n",
    "    label_grid_bce = label_grid_bce.reset_index().drop('index', axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(9,3))\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.xticks(ticks=np.arange(0,110,10), labels=np.arange(0,110,10)/100, fontsize=10)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('Performance curves - Label '+str(l)+' ('+label_names[l]+')\\nMacro Soft-F1', fontsize=10)\n",
    "    label_grid.plot(ax=ax)\n",
    "    \n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    plt.xticks(ticks=np.arange(0,110,10), labels=np.arange(0,110,10)/100, fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('Performance curves - Label '+str(l)+' ('+label_names[l]+')\\nBCE', fontsize=10)\n",
    "    label_grid_bce.plot(ax=ax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Something interesting is happening here!**  \n",
    "When training the model using the macro soft-F1 loss, we get an F1-score that is almost independent of the threshold. We don't have this effect when using the binary cross-entropy loss. It is actually an interesting effect because it offers the possibility to fix the threshold at 0.5 for all labels and still get a performance close to the one we would obtain by searching for an optimal threshold when using the BCE loss. When it comes to building production ML systems, this is a very nice feature. Updating the thresholds and making sure they remain optimal on new coming data is a lot of effort. Using the macro soft-F1 loss can help solve that problem, but actually where does that behaviour come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand why the perfomance is so stable and does not rely on the threshold when optimizing directly for F1-score.  \n",
    "It would be interesting to analyze the spread of prabability values that come out of the neural network in each of both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set with both models\n",
    "y_hat_val = model.predict(val_ds)\n",
    "y_hat_val_bce = model_bce.predict(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the histogram of label probability values with each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use(\"default\")\n",
    "for l in top5:\n",
    "        \n",
    "    plt.figure(figsize=(9,3))\n",
    "    \n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.xticks(ticks=np.arange(0,1.1,0.1), fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('Probability distribution - Label '+str(l)+' ('+label_names[l]+')\\nMacro Soft-F1', fontsize=10)\n",
    "    plt.xlim(0,1)\n",
    "    ax = sns.distplot(y_hat_val[:,l], bins=30, kde=True, color=\"g\")\n",
    "    \n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    plt.xticks(ticks=np.arange(0,1.1,0.1), fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('Probability distribution - Label '+str(l)+' ('+label_names[l]+')\\nBCE', fontsize=10)\n",
    "    plt.xlim(0,1)\n",
    "    ax = sns.distplot(y_hat_val_bce[:,l], bins=30, kde=True, color=\"b\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Alright, it may look more clear now.**  \n",
    "When training using the binary cross-entropy loss, the probability distribution of the output has some gaussian properties (notice the bell shape of the blue histograms). Actually, this optimization learns from the original distribution of the data. We can see that for label 'Drama' which coveres 50% of the dataset, the probability distribution is centred at 0.5. By the way, the classifier that was built for 'Drama' appears to be very weak as both classes do not appear to be separated in probability values. We can also notice that the less frequent a label is, the more shifted to the left the distribution will be. For example, probability scores appear to be very low for 'Crime' and this label coveres only 14% of the dataset. The model learns from this rarity to predict lower probability values. On the other hand, when using the macro soft-F1 loss, we are creating a system that does not reflect the same magnitude of conditional probability values. Instead, it learns to be less hesitating and generates predictions that are either very close to 1 or very close to 0. We have less probability values in the middle range. So, the performance does not change too much when varying the threshold in that range.  \n",
    "> Optimizing with the macro soft-F1 loss could replace some exhaustive techniques like:\n",
    "* Searching for the optimal decision threshold that maximizes performance on a validation set\n",
    "* Calibrating probability values by oversampling a minority class or undersampling a majority class before training (very complex in case of multi-label classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Show predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try and see what the predictions will look like when using our model on posters of some known movies.  \n",
    "The following function simplifies the process of preparing poster data, generating the prediction from the model and visualizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(title, movies_df, model):\n",
    "    \n",
    "    # Get movie info\n",
    "    imdbId = movies.loc[movies['Title']==title]['imdbId'].iloc[0]\n",
    "    genre = movies.loc[movies['Title']==title]['Genre'].iloc[0]\n",
    "    img_path = os.path.join('./data/movie_poster/images', str(imdbId)+'.jpg')\n",
    "\n",
    "    # Read and prepare image\n",
    "    img = image.load_img(img_path, target_size=(IMG_SIZE,IMG_SIZE,CHANNELS))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Generate prediction\n",
    "    prediction = (model.predict(img) > 0.5).astype('int')\n",
    "    prediction = pd.Series(prediction[0])\n",
    "    prediction.index = mlb.classes_\n",
    "    prediction = prediction[prediction==1].index.values\n",
    "\n",
    "    # Dispaly image with prediction\n",
    "    style.use('default')\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(Image.open(img_path))\n",
    "    plt.title('\\n\\n{}\\n\\nGenre\\n{}\\n\\nPrediction\\n{}\\n'.format(title, genre, list(prediction)), fontsize=9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over some movie titles and show the predicted genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Clash of the Titans (2010)\",\n",
    "          \"An Affair of Love (1999)\",\n",
    "          \"Dragon Ball: Episode of Bardock (2011)\",\n",
    "          \"L'Amour au temps de la guerre civile (2014)\",\n",
    "          \"Paranormal Activity: The Marked Ones (2014)\",\n",
    "          \"Chef (2014)\"]\n",
    "\n",
    "for t in titles:\n",
    "    show_prediction(t, movies, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having trained and evaluated the two models, we can export them as a TensorFlow saved model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1 #datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "export_path = \"./models/soft-f1_{}\".format(t)\n",
    "model.save(export_path)\n",
    "#tf.keras.experimental.export_saved_model(model, export_path)\n",
    "print(\"Model with macro soft-f1 was exported in this path: '{}'\".format(export_path))\n",
    "\n",
    "export_path_bce = \"./models/bce_{}\".format(t)\n",
    "model = tf.keras.models.load_model(export_path)\n",
    "#tf.keras.models.load_model(model_bce, export_path_bce)\n",
    "print(\"Model with bce was exported in this path: '{}'\".format(export_path_bce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can later reload a tf.keras model by specifying the path to the export directory containing the .pb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = tf.keras.experimental.load_from_saved_model(export_path, custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Multi-label classification**: When the number of possible labels for an observation is greater than one, we should rely on multiple logistic regressions to solve many independant binary classification problems. The advantage  of using neural networks is that we can solve these many problems at the same time inside the same model. Mini-batch learning helps reduce memory complexity while training.\n",
    "\n",
    "* **Using TensorFlow data API**:  tf.data makes it possible to build fast input pipelines for training and evaluating TensorFlow models. Using the tf.data.Dataset abstraction, we can collect observations as a pair of tensor components representing the image and its labels, preprocess them in parallel and do the necessary shuffling and batching in a very easy manner.\n",
    "\n",
    "* **Using TensorFlow Hub**:  Transfer learning has never been this simple. TF.Hub provides reusable components from large pre-trained ML models. We could load a MobileNet feature extractor wrapped as keras layer and attach our own fully connected layers on top. The pre-trained model was frozen and only the weights of our classification layers were updated during training.\n",
    "\n",
    "* **Optimizing directly for macro F1**: By introducing the macro soft-F1 loss, we could train the model to directly increase the metric we care about: the macro F1-score @ threshold 0.5. We could clearly observe the alignment during training and evaluation on successive epochs. When using this loss, we do not have to tune the decision threshold any more. Imagine a multi-label classification system with hundreds of labels, how unstable the system will be if we have to continuously update the optimal threshold for each label. The macro soft-F1 loss comes to the rescue. By using it, we can keep all thresholds fixed at 0.5 and still get an optimal performance from the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
